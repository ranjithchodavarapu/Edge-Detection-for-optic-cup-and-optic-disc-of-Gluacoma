{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473a3cd0-d04e-40de-afc6-f21c72d97b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup\n",
    "\n",
    "train=True\n",
    "Epochs=30\n",
    "preload=False\n",
    "hough=False\n",
    "rams=False\n",
    "dynAug=False\n",
    "depth = 6\n",
    "chan = 64\n",
    "ir = 1.1\n",
    "rand_sv = 42\n",
    "ds = 'MIX'\n",
    "zone = 'CUP'\n",
    "cup = True\n",
    "mix = True\n",
    "dri = False\n",
    "rim = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923b8d57-3238-4a9e-85b4-e747145880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "import skimage.transform\n",
    "import skimage.measure\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers as layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, LSTM, Lambda, UpSampling2D, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89ddbeda-c121-465e-8bd7-207f1ecbf4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import concatenate,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20abe764-5e55-4302-b5b0-f094c378ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice_coef(y_true, y_pred))\n",
    "\n",
    "# Computes mean Intersection-over-Union (IOU) for two arrays of binary images.\n",
    "\n",
    "def iou_loss_core(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160a30e8-981d-4399-bc03-f4618fc5c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to increase the brightness\n",
    "# hue, saturation, value\n",
    "\n",
    "def modify_brightness_p(img, p=1.2):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 1.0/p\n",
    "    v[v > lim] = 1.0\n",
    "    v[v <= lim] *= p\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR).clip(min=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fece6269-b2c5-434f-90e3-1fc2769d21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index512_resize(index,top):\n",
    "    index=index*top/512\n",
    "    return int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5cabe9-8db3-4188-a777-45d70e39b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper code to shuffle instead of random shuffle \n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c8db55-ecb4-4a34-a4ee-ac600b7dbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bebf496-c38b-477a-b400-4bafc49c1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "\n",
    "h5f2 = h5py.File(os.path.join(os.path.dirname(os.getcwd()), r'C:\\Users\\Ranjith ch\\Desktop\\code\\glucoma\\model\\data', 'DRISHTI_GS.hdf5'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a49251b5-7867-4828-bae7-2553618efac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n",
      "(50, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# DRISHTI Dataset\n",
    "# step1: prepare the data for our model injection\n",
    "\n",
    "Xori= np.asarray(h5f2['DRISHTI-GS/orig/images'])\n",
    "disc_locations = np.asarray( h5f2['DRISHTI-GS/512 px/disc_locations'])\n",
    "FC = np.asarray(h5f2['DRISHTI-GS/512 px/file_codes'] ) \n",
    "indDRI = np.arange(0,Xori.shape[0])\n",
    "bsqside=np.maximum((disc_locations[:,3]-disc_locations[:,1]),(disc_locations[:,2]-disc_locations[:,0]))\n",
    "isize=Xori.shape[1]\n",
    "\n",
    "if (cup):\n",
    "  \n",
    "  Yf = np.asarray(h5f2['DRISHTI-GS/512 px/cup'])\n",
    " \n",
    "  Xc = [Xori[i][index512_resize(disc_locations[i][0],isize):index512_resize(disc_locations[i][0]+bsqside[i],isize), index512_resize(disc_locations[i][1],isize):index512_resize(disc_locations[i][1]+bsqside[i],isize)] \n",
    "                   for i in range(len(Xori))]\n",
    "\n",
    "  Yc=[Yf[i][disc_locations[i][0]:disc_locations[i][0]+bsqside[i], disc_locations[i][1]:disc_locations[i][1]+bsqside[i]] \n",
    "                   for i in range(len(Xori))]\n",
    "\n",
    "else:\n",
    "  Yf =np.asarray( h5f2['DRISHTI-GS/512 px/disc'])\n",
    "  \n",
    "  Xc = [Xori[i][index512_resize(50,isize):index512_resize(462,isize), index512_resize(50,isize):index512_resize(462,isize)] \n",
    "                   for i in range(len(Xori))]\n",
    "\n",
    "  Yc=[Yf[i][50:462,50:462] \n",
    "                   for i in range(len(Xori))]\n",
    "\n",
    "X=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST) for img in Xc]\n",
    "X=np.asarray(X) \n",
    "am=np.amax(X)\n",
    "X=X.astype(np.float32)/am \n",
    "print(np.amax(X),np.amin(X))\n",
    "\n",
    "Y=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST)[..., None] for img in Yc]\n",
    "Y=np.asarray(Y) \n",
    "ym=np.amax(Y) \n",
    "Yf=Y/ym\n",
    "#get binary mask\n",
    "Yb=(Y>0.5).astype(np.float32) \n",
    "\n",
    "print(np.amax(Yf),np.amin(Yf))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29db75a4-cb5d-49de-aa1d-095cd4c2fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2: Create train and test set by combining datasets\n",
    "\n",
    "rng = np.random.RandomState(rand_sv)\n",
    "\n",
    "#DRISHTI\n",
    "X_train1t, X_test1t, Y_train1t, Y_test1t, F_train1t, F_test1t ,ind_train1, ind_test1= train_test_split( X, Yb, FC, indDRI,test_size=0.25,random_state=rng)\n",
    "\n",
    "X_test_dri=np.copy(X_test1t)\n",
    "Y_test_dri=np.copy(Y_test1t)\n",
    "F_test_dri=np.copy(F_test1t)\n",
    "\n",
    "\n",
    "if(dri or mix):\n",
    "  X_train1=np.concatenate([X_train1t,X_train1t])\n",
    "  X_train1=np.concatenate([X_train1,X_train1t])\n",
    "  X_test1=np.concatenate([X_test1t,X_test1t])\n",
    "  X_test1=np.concatenate([X_test1,X_test1t])\n",
    "\n",
    "  Y_train1=np.concatenate([Y_train1t,Y_train1t])\n",
    "  Y_train1=np.concatenate([Y_train1,Y_train1t])\n",
    "  Y_test1=np.concatenate([Y_test1t,Y_test1t])\n",
    "  Y_test1=np.concatenate([Y_test1,Y_test1t])\n",
    "\n",
    "\n",
    "if(dri):\n",
    "  X_train1=np.concatenate([X_train1,X_train1])\n",
    "  Y_train1=np.concatenate([Y_train1,Y_train1])\n",
    "\n",
    "X_train1=np.asarray(X_train1)\n",
    "Y_train1=np.asarray(Y_train1)\n",
    "X_test=np.asarray(X_test1)\n",
    "Y_test=np.asarray(Y_test1)\n",
    "\n",
    "X_train=np.copy(X_train1)\n",
    "Y_train=np.copy(Y_train1)\n",
    "\n",
    "size=X_train1.shape[0]\n",
    "\n",
    "X_traine=np.empty((20*size, 128, 128, 3),dtype=np.float32)\n",
    "Y_traine=np.empty((20*size, 128, 128, 1),dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e17170c-a72f-4425-8293-02c01fc66a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d97127381f041e9b2241f137bd2bf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8b3475a7ef4a32a2d4861137b56ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step3: Preprocessing step for Cup Segmentation\n",
    "# Perform CLAHE on each image\n",
    "\n",
    "for i in range(16):\n",
    "  X_traine[i*size:(i+1)*size]=X_train1\n",
    "  Y_traine[i*size:(i+1)*size]=Y_train1\n",
    "  \n",
    "base= 16*size\n",
    "\n",
    "for j in tqdm_notebook(range(X_train1.shape[0])):\n",
    "  X_traine[base]=skimage.exposure.equalize_adapthist(X_train1[j], clip_limit=0.04)\n",
    "  Y_traine[base]=Y_train1[j]\n",
    "  base+=1\n",
    "  X_traine[base]=skimage.exposure.equalize_adapthist(X_train1[j], clip_limit=0.02)\n",
    "  Y_traine[base]=Y_train1[j]\n",
    "  base+=1\n",
    "  X_traine[base]=modify_brightness_p(X_train1[j],0.9)\n",
    "  Y_traine[base]=Y_train1[j]\n",
    "  base+=1\n",
    "  X_traine[base]=modify_brightness_p(X_train1[j],1.1)\n",
    "  Y_traine[base]=Y_train1[j]\n",
    "  base+=1\n",
    "  \n",
    "X_testc=np.copy(X_test)\n",
    "Y_testc=np.copy(Y_test)\n",
    "\n",
    "sizev=X_testc.shape[0]\n",
    "\n",
    "X_teste=np.empty((20*sizev, 128, 128, 3),dtype=np.float32)\n",
    "Y_teste=np.empty((20*sizev, 128, 128, 1),dtype=np.float32)\n",
    "\n",
    "for i in range(8):\n",
    "  X_teste[i*sizev:(i+1)*sizev]=X_testc\n",
    "  Y_teste[i*sizev:(i+1)*sizev]=Y_testc\n",
    "  \n",
    "basev= 8*sizev\n",
    "\n",
    "for j in tqdm_notebook(range(X_testc.shape[0])):\n",
    "  X_teste[basev]=skimage.exposure.equalize_adapthist(X_testc[j], clip_limit=0.04)\n",
    "  Y_teste[basev]=Y_testc[j]\n",
    "  basev+=1\n",
    "  X_teste[basev]=skimage.exposure.equalize_adapthist(X_testc[j], clip_limit=0.02)\n",
    "  Y_teste[basev]=Y_testc[j]\n",
    "  basev+=1\n",
    "  X_teste[basev]=modify_brightness_p(X_testc[j],0.9)\n",
    "  Y_teste[basev]=Y_testc[j]\n",
    "  basev+=1\n",
    "  X_teste[basev]=modify_brightness_p(X_testc[j],1.1)\n",
    "  Y_teste[basev]=Y_testc[j]\n",
    "  basev+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bef26e0-a827-4d50-9e9e-cc365d5bfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4: Shuffle the dataset\n",
    "\n",
    "X_trains,Y_trains = unison_shuffled_copies(X_traine, Y_traine)\n",
    "X_tests,Y_tests = unison_shuffled_copies(X_teste, Y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49060b42-b55d-45de-b10f-983742495ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_block_names(stage):\n",
    "    conv_name = 'decoder_stage{}_conv'.format(stage)\n",
    "    bn_name = 'decoder_stage{}_bn'.format(stage)\n",
    "    relu_name = 'decoder_stage{}_relu'.format(stage)\n",
    "    up_name = 'decoder_stage{}_upsample'.format(stage)\n",
    "    return conv_name, bn_name, relu_name, up_name\n",
    "\n",
    "\n",
    "def Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                     batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n",
    "\n",
    "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'1')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "\n",
    "def Transpose2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                      transpose_kernel_size=(4,4), batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n",
    "\n",
    "        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate,\n",
    "                            padding='same', name=up_name)(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "163a7fa5-c2df-4056-91df-98a0acd1b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(backbone, classes, last_block_filters, skip_layers,\n",
    "               n_upsample_blocks=5, upsample_rates=(2,2,2,2,2),\n",
    "               block_type='upsampling', activation='sigmoid',\n",
    "               **kwargs):\n",
    "\n",
    "    input = backbone.input\n",
    "    x = backbone.output\n",
    "\n",
    "    if block_type == 'transpose':\n",
    "        up_block = Transpose2D_block\n",
    "    else:\n",
    "        up_block = Upsample2D_block\n",
    "\n",
    "    # convert layer names to indices\n",
    "    skip_layers = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n",
    "                    for l in skip_layers])\n",
    "    for i in range(n_upsample_blocks):\n",
    "\n",
    "        # check if there is a skip connection\n",
    "        if i < len(skip_layers):\n",
    "#             print(backbone.layers[skip_layers[i]])\n",
    "#             print(backbone.layers[skip_layers[i]].output)\n",
    "            skip = backbone.layers[skip_layers[i]].output\n",
    "        else:\n",
    "            skip = None\n",
    "\n",
    "        up_size = (upsample_rates[i], upsample_rates[i])\n",
    "        filters = last_block_filters * 2**(n_upsample_blocks-(i+1))\n",
    "\n",
    "        x = up_block(filters, i, upsample_rate=up_size, skip=skip, **kwargs)(x)\n",
    "\n",
    "    if classes < 2:\n",
    "        activation = 'sigmoid'\n",
    "\n",
    "    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n",
    "    x = Activation(activation, name=activation)(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cab7ebb-02c3-4b7c-913b-082b1cb66daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.set_image_data_format(\"channels_last\"):\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, block_fn, repetitions,input_tensor):\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.set_image_data_format(\"channels_last\"):\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "        \n",
    "        if input_tensor is None:\n",
    "            img_input = Input(shape=input_shape)\n",
    "        else:\n",
    "            if not K.is_keras_tensor(input_tensor):\n",
    "                img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "            else:\n",
    "                img_input = input_tensor\n",
    "                \n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(img_input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        model = Model(inputs=img_input, outputs=block)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape,input_tensor):\n",
    "        return ResnetBuilder.build(input_shape, basic_block, [3, 4, 6, 3],input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a852e22e-7dd6-4c93-8722-465f1534e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UResNet34(input_shape=(None, None, 3), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n",
    "                       encoder_weights=None, input_tensor=None, activation='sigmoid', **kwargs):\n",
    "\n",
    "    backbone = ResnetBuilder.build_resnet_34(input_shape=input_shape,input_tensor=input_tensor)\n",
    "\n",
    "    skip_connections = list([97,54,25])  # for resnet 34\n",
    "    model = build_unet(backbone, classes, decoder_filters,\n",
    "                       skip_connections, block_type=decoder_block_type,\n",
    "                       activation=activation, **kwargs)\n",
    "    model.name = 'u-resnet34'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0e563f-fe2d-47a9-917d-33e29943e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = rand_sv\n",
    "batch_s = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecb1bd2-659d-4009-837c-dc6f62adae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for ipython notebook\n",
    "\n",
    "cp_callbacks = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(r'C:\\Users\\Ranjith ch\\Desktop\\code\\glucoma\\cnn\\plus_check.hdf5'), verbose=1, save_best_only=True,save_weights_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, min_lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b0d0ae-87f1-4aac-b51a-5624dec80d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The argument `strides` cannot contains 0(s). Received: (2, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/1829626243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUResNet34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2695315519.py\u001b[0m in \u001b[0;36mUResNet34\u001b[1;34m(input_shape, classes, decoder_filters, decoder_block_type, encoder_weights, input_tensor, activation, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m                        encoder_weights=None, input_tensor=None, activation='sigmoid', **kwargs):\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbackbone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResnetBuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_resnet_34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mskip_connections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m97\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m54\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# for resnet 34\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2379130606.py\u001b[0m in \u001b[0;36mbuild_resnet_34\u001b[1;34m(input_shape, input_tensor)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_resnet_34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mResnetBuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasic_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2379130606.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(input_shape, block_fn, repetitions, input_tensor)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_residual_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_first_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mfilters\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2379130606.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_first_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0minit_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             input = block_function(filters=filters, init_strides=init_strides,\n\u001b[0m\u001b[0;32m    103\u001b[0m                                    is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2379130606.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bn_relu_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_shortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RANJIT~1\\AppData\\Local\\Temp/ipykernel_18192/2379130606.py\u001b[0m in \u001b[0;36m_shortcut\u001b[1;34m(input, residual)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# 1 X 1 conv if shape is different. Else identity.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride_width\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstride_height\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mequal_channels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n\u001b[0m\u001b[0;32m     65\u001b[0m                           \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                           \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstride_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                **kwargs):\n\u001b[1;32m--> 671\u001b[1;33m     super(Conv2D, self).__init__(\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_causal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'causal'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_channels_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m_validate_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       raise ValueError('The argument `strides` cannot contains 0(s). '\n\u001b[0m\u001b[0;32m    178\u001b[0m                        'Received: %s' % (self.strides,))\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The argument `strides` cannot contains 0(s). Received: (2, 0)"
     ]
    }
   ],
   "source": [
    "model = UResNet34(input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc5010-47a4-4135-977c-23541b0e3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
